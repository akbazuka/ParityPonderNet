{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBBJ12OJai9o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\"\"\"\n",
        "Creating custom dataset for the task that is readable by the dataloader:\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\"\"\"\n",
        "class CustomData(torch.utils.data.Dataset):\n",
        "    def __init__(self, feature_len, sample_size, seed=0):\n",
        "        np.random.seed(seed)  #Init random seed\n",
        "\n",
        "        self.feature_len = feature_len\n",
        "        self.sample_size = sample_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sample_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Generate the feature vector; random vector containing a vector of \n",
        "        vec_len elements with values of either -1.0, 0.0 or 1.0\n",
        "        '''\n",
        "        features = [np.random.choice([-1.0, 0.0, 1.0], 1)[0] \n",
        "                    for _ in range(self.feature_len)]\n",
        "        target = sum([True if x == 1.0 else False for x in features]) % 2       #Calculate the parity of the vector; count the no. of instances of 1.0\n",
        "        return torch.Tensor(features), target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeeonElgakjh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Create the Ponder Network that learns the optimal no. of iterations for the parity task\n",
        "\"\"\"\n",
        "class ParityPonderNetwork(nn.Module):\n",
        "    def __init__(self, feature_len, nn_cell, ponder_steps, hidden_layers, \n",
        "                 seed=0):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(seed)                                                 #Set seed in pytorch for reproducibility \n",
        "        self.ponder_steps = ponder_steps                                        #No. of steps to ponder for during training (no. of iterations to run)\n",
        "        self.hidden_layers = hidden_layers                                      #No. of hidden layers\n",
        "        self.out_l = nn.Linear(hidden_layers, 1)                                #Will output the y_hat (prediction)\n",
        "        self.lamb_l = nn.Linear(hidden_layers, 1)                               #Will output the lambda (halting prob.)\n",
        "        self.step_fn = nn_cell(feature_len, hidden_layers)                      #Instantiate the NN cell\n",
        "\n",
        "    def forward(self, x, is_prediction=False, demo=False, demo_halting=False):\n",
        "        hidden_state = torch.zeros(x.shape[0], self.hidden_layers, \n",
        "                                   device=x.device)                             #Init the hidden state to zeros\n",
        "        p_not_halted = torch.ones(x.shape[0], device=x.device)                  #Helper tensor that is updated dynamically, which stores the prob. that we have not yet halted\n",
        "        batch_halt_idx = torch.zeros(x.shape[0], device=x.device)               #Init the halting steps for each batch to 0 to later store them\n",
        "        predictions = torch.ones(self.ponder_steps,x.shape[0], \n",
        "                                 device=x.device)*10                            #Store the predictions at each step; init to all 10s to filter out unused rows easily\n",
        "        probabilities = torch.zeros(self.ponder_steps,x.shape[0],\n",
        "                                    device=x.device)*10                         #Store the probabilities at each step; \"\"\n",
        "        step_lambda = torch.ones((x.shape[0],))                                 #Keep track of the lambdas at each iteration\n",
        "        \n",
        "        halting_step = self.ponder_steps                                        #To return of the halting step (if prediction)\n",
        "        \n",
        "        #Run the forward pass for the number of specified ponder steps\n",
        "        for ponder_step in range(self.ponder_steps):\n",
        "            if (demo):\n",
        "                print(f\"**********************************************PONDER STEP {ponder_step}**************************************************\\n\")\n",
        "            \n",
        "            predictions[ponder_step] = self.out_l(hidden_state)[:, 0]           #Get the new predictions and store them\n",
        "                    \n",
        "            '''Generate the lambdas; Run the hidden state through the \n",
        "            lambda layer and the sigmoid activation function \n",
        "            to return values between 0 and 1; generate next lambdas\n",
        "            And if final pass, set lambdas to vector of 1s on the \n",
        "            final pass to make sure it stops\n",
        "            '''\n",
        "            step_lambda = torch.sigmoid(self.lamb_l(hidden_state))[:, 0] \\\n",
        "                if (ponder_step != self.ponder_steps-1) else  \\\n",
        "                    x.new_ones(x.shape[0])\n",
        "            \n",
        "            probabilities[ponder_step] = p_not_halted*step_lambda               #Calculate hte probability that we will stop at the current step and store it\n",
        "\n",
        "            hidden_state = self.step_fn(x, hidden_state)                        #Generate new hidden state; always feeding the entire original feature vector into the cell\n",
        "            if (demo):\n",
        "                print(f\"The hidden states are: {hidden_state}\\n\")\n",
        "            \n",
        "            p_not_halted = p_not_halted * (1-step_lambda)                       #Update the unhalted probs.; prob. of not halting at the step is 1-prob. of halting\n",
        "\n",
        "            bernoulli_sample = torch.bernoulli(step_lambda)                     #Randomly generate binary tensor from a Bernoulli distribution using lambda as probabilies for each batch\n",
        "            if (demo):\n",
        "                print(f\"The lambdas are: {step_lambda}\\n\")\n",
        "                print(f\"Bernoulli sample: {bernoulli_sample}\")\n",
        "\n",
        "            bernoulli_step = bernoulli_sample * (ponder_step + 1)               #Have every '1' value represent the current ponder step by mult. it with the step number\n",
        "\n",
        "            '''Update the halting step to the current step for each batch if \n",
        "            the bernoulli sample generated a 1 for the current batch, which\n",
        "            would have been a result of a high lambda for the batch (high prob)\n",
        "            '''\n",
        "            unhalted_batches = (batch_halt_idx == 0).nonzero(as_tuple=True)\n",
        "            for i in unhalted_batches:\n",
        "                batch_halt_idx[i] = bernoulli_step[i]\n",
        "\n",
        "            if (demo):\n",
        "                print(f\"The batch halt indeces are: {batch_halt_idx}\\n\")\n",
        "                print(f\"The unhalted probabilities are: {p_not_halted}\\n\")\n",
        "\n",
        "            halted_batch_count = torch.count_nonzero(batch_halt_idx).item()     #Check if all of the batches have halted\n",
        "            if (is_prediction and halted_batch_count == x.shape[0]):            #Stop the loop if all batches have halted and model is trying to make a prediction (not train)\n",
        "\n",
        "                if (demo_halting):\n",
        "                    print(f\"The halted batch indeces are: {batch_halt_idx}\")\n",
        "                    print(f\"The batch was halted at ponder step: {ponder_step}\\n\")\n",
        "\n",
        "                predictions = predictions[predictions.sum(dim=1) != \n",
        "                    10*x.shape[0]]                                              #Return tensor of predictions up until stopping step\n",
        "                probabilities = probabilities[probabilities.sum(dim=1) != \n",
        "                    10*x.shape[0]]                                              #Return tensor of predictions up until stopping step\n",
        "                halting_step = ponder_step\n",
        "                break\n",
        "            \n",
        "            if (demo):\n",
        "                print(f\"The predictions are: {predictions}\\n\")\n",
        "                print(f\"The probabilities are: {probabilities}\\n\")\n",
        "\n",
        "        return predictions, probabilities, batch_halt_idx, halting_step\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufj6Y8Z7a2Ta"
      },
      "outputs": [],
      "source": [
        "class PonderLoss(nn.Module):\n",
        "    def __init__(self, ponder_steps, loss_fn, geo_lambda, beta):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loss_fn = loss_fn                                                  #Define the loss function (can just define here instead of making it an input param)\n",
        "        self.geometric_probs = []                                               #Init a tensor of zeros that we want to iteratively populate\n",
        "        p_not_halted = 1.0                                                      #Represents the helper prob. that we have not halted yet\n",
        "\n",
        "        '''For each sample, calculate the prob. of halting at the kth step is the \n",
        "        prob that we have not yet halted at any one of the previous steps and \n",
        "        that we will halt on the kth step\n",
        "        '''\n",
        "        for _ in range(ponder_steps):\n",
        "            self.geometric_probs.append(p_not_halted * geo_lambda)\n",
        "            p_not_halted = p_not_halted * (1-geo_lambda)                        #Update the probs. of not halting; this follows a geometric distribution as it continuously reduces\n",
        "\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, halt_probs, targets, predictions, demo_rec=False, \n",
        "                demo_reg=False):\n",
        "        '''For each ponder step, compare the target values with the predictions \n",
        "        and weight them based on the geometric probability distribution.\n",
        "        '''\n",
        "        loss_val = torch.tensor(0.0, device=halt_probs.device, \n",
        "                                requires_grad=True)                             #Init the total loss\n",
        "\n",
        "        if (demo_rec):\n",
        "            print(f\"The probabilities are: {halt_probs}\")\n",
        "        elif (demo_reg):\n",
        "            print(f\"The probabilities are: {halt_probs.transpose(0,1)}\")\n",
        "        \n",
        "        '''\n",
        "        For each step, compare the ground truth with the prediction and weight it based\n",
        "        on the probability distribution; Reconstruction Loss\n",
        "        '''\n",
        "        for ponder_step in range(halt_probs.shape[0]):\n",
        "            sample_loss = self.loss_fn(predictions[ponder_step], targets)       #Return the gross loss between the predictiona and targets\n",
        "            weighted_loss = sample_loss * halt_probs[ponder_step]               #Calculate the weighted loss using the halting probabilities; stricter as probability comes closer to halting (assigns higher weighting for samples that have almost stopped)\n",
        "            loss_val = torch.mean(weighted_loss) + loss_val                     #Aggregate the mean loss at the ponder step to the total reconstruction loss\n",
        "            if (demo_rec):\n",
        "                print(f\"BCE loss at step {ponder_step} = {sample_loss}\")\n",
        "                print(f\"Weighted loss at step {ponder_step} = {weighted_loss}\")\n",
        "\n",
        "        if (demo_rec):\n",
        "            print(f\"\\nThe reconstruction loss is: {loss_val}\\n\\n\")\n",
        "\n",
        "        #Expand the pre-computed geometric distribution tensor across all samples; repeat the same tensor across all the batches\n",
        "        batch_geometric_probs = torch.zeros((halt_probs.shape[1], halt_probs.shape[0]), device=halt_probs.device)\n",
        "        for batch_no in range(batch_geometric_probs.shape[0]):\n",
        "            batch_geometric_probs[batch_no] = torch.tensor(\n",
        "                self.geometric_probs)                                           #Index from None in order to force array to become 2d     \n",
        "\n",
        "        if (demo_reg):\n",
        "            print(f\"Batch geo probs: {batch_geometric_probs}\\n\") \n",
        "\n",
        "        '''https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html\n",
        "        Calculate the Kullback-Leibler divergence loss to force the \n",
        "        probabilities to follow a geometric distribution; Regularisation Loss\n",
        "        '''\n",
        "        kl_div_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")(torch.log(halt_probs.transpose(0, 1)), batch_geometric_probs)\n",
        "\n",
        "        if (demo_reg):  \n",
        "            print(f\"The regularisation loss is: {kl_div_loss}\\n\\n\")\n",
        "\n",
        "        return loss_val + self.beta*kl_div_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHDVJ4uba5Sk"
      },
      "outputs": [],
      "source": [
        "def train(batch_size=128, feature_len=8, hidden_layers=64, geo_lambda=0.3, \n",
        "          ponder_steps=20, beta=0.01, learning_rate=3*10**(-4), epochs=150000, seed=0):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_set = CustomData(feature_len, batch_size*epochs, seed)                #Generate training data\n",
        "    train_data = torch.utils.data.DataLoader(train_set, \n",
        "                    batch_size=batch_size, num_workers=2)                       #Create dataloader for training data\n",
        "    \n",
        "    eval_set = CustomData(feature_len, 45*15, seed)                             #Generate evaluation data\n",
        "    eval_data = torch.utils.data.DataLoader(eval_set, batch_size=45,\n",
        "                                            num_workers=2)\n",
        "\n",
        "    model = ParityPonderNetwork(feature_len, nn.GRUCell, ponder_steps, \n",
        "                hidden_layers, seed=seed).to(device, torch.float32)             #Init the model wth GRU step-function                  \n",
        "    \n",
        "    model_loss = PonderLoss(ponder_steps, \n",
        "                    nn.BCEWithLogitsLoss(reduction='none'), \n",
        "                        geo_lambda, beta).to(device, torch.float32)             #Init the model loss with binary cross-entropy\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)          #Init the optimizer with Adam algorithm\n",
        "\n",
        "    loss_tracker = []                                                           #Keep track of loss at every n iterations\n",
        "    valid_accuracy = []                                                         #Keep track of overall accuracy when performing validation\n",
        "    valid_avg_halting = []                                                      #Keep track of the average halting step when performing validation\n",
        "    ponder_valid_acc = []                                                       #Keep track of per-ponder-step accuracy\n",
        "    ponder_valid_avg_prob = []                                                  #Keep track of per-ponder-step average halting step\n",
        "\n",
        "    '''\n",
        "    Train the model\n",
        "    '''\n",
        "    model.train()                                                               #Put the model in training mode\n",
        "    for i, t_data in enumerate(train_data):\n",
        "        #Copy data to GPU\n",
        "        features, labels = t_data\n",
        "        features, labels = features.to(device, torch.float32), labels.to(device, \n",
        "                            torch.float32)\n",
        "        \n",
        "        predictions, probabilities, _, _ = model(features)                      #Run forward propogation for PonderNet\n",
        "\n",
        "        loss = model_loss(probabilities, labels, predictions)                   #Compute the total loss of the predictions\n",
        "\n",
        "        #Store outputs every 1000 iterations\n",
        "        if (i % 1000 == 0):\n",
        "            loss_tracker.append(loss.item())\n",
        "            print(f\"The loss at epoch {i} is: {loss}\")\n",
        "\n",
        "        '''Set the gradients to 0, compute the gradients and take the gradient \n",
        "        descent step.\n",
        "        ''' \n",
        "        optimizer.zero_grad()                                                   #Clear gradients\n",
        "        loss.backward()                                                         #Compute the gradients\n",
        "        optimizer.step()                                                        #Update the parameters\n",
        "\n",
        "        #Perform validation at every 5000 epochs\n",
        "        if (i % 4000 == 0):\n",
        "            model.eval()                                                        #Put the model in evaluation mode\n",
        "\n",
        "            with torch.no_grad():                                               #Don't update the model's gradients\n",
        "                epoch_valid_acc = []\n",
        "                epoch_valid_avg_halt = []\n",
        "                epoch_sample_valid_acc = []\n",
        "                epoch_sample_valid_avg_prob = []\n",
        "\n",
        "                for v_data in eval_data:\n",
        "                    features, labels = v_data\n",
        "                    features, labels = (features.to(device, torch.float32), \n",
        "                                        labels.to(device, torch.float32))\n",
        "\n",
        "                    valid_preds, valid_probs, vaild_batch_halt_idx, _ = (\n",
        "                        model(features))                                        #Get outputs from model\n",
        "\n",
        "                    '''https://pytorch.org/docs/stable/generated/torch.gather.html\n",
        "                    torch.gather uses the indeces passed to retrieve from the \n",
        "                    row and the column index of the index to retrieve from the \n",
        "                    column of the passed vector (in this case)\n",
        "                    '''\n",
        "                    vaild_batch_halt_preds = torch.gather(valid_preds, 0, \n",
        "                        vaild_batch_halt_idx[None, :].to(torch.int64)-1)[0]\n",
        "\n",
        "                    #Calculate and store the mean accuracy of halted predicitons against the labels \n",
        "                    epoch_valid_acc.append(np.mean([1 \n",
        "                        if ((vaild_batch_halt_preds[x] > 0) == labels[x]) \n",
        "                            else 0 for x in range(\n",
        "                                vaild_batch_halt_preds.shape[0])]))\n",
        "\n",
        "                    #Compute and store the average halting step over batches\n",
        "                    epoch_valid_avg_halt.append(\n",
        "                        np.mean(vaild_batch_halt_idx.tolist()))\n",
        "\n",
        "                    #Compute the accuracy at each ponder step over batches\n",
        "                    epoch_sample_valid_acc.append(np.mean([[True \n",
        "                        if ((valid_preds[x][z] > 0) == labels[z]) else False\n",
        "                            for z in range(valid_preds.shape[1])] \n",
        "                                for x in range(valid_preds.shape[0])], 1))\n",
        "                    \n",
        "                    #Compute and store the mean probability for halting at each step\n",
        "                    epoch_sample_valid_avg_prob.append(\n",
        "                        np.mean(valid_probs.tolist(), 1))\n",
        "\n",
        "                #Store mean stats from current evaluation iteration\n",
        "                valid_accuracy.append(np.mean(epoch_valid_acc))\n",
        "                valid_avg_halting.append(np.mean(epoch_valid_avg_halt))\n",
        "                ponder_valid_acc.append(np.mean(epoch_sample_valid_acc, 0))\n",
        "                ponder_valid_avg_prob.append(\n",
        "                    np.mean(epoch_sample_valid_avg_prob, 0))\n",
        "                print(f\"\\nThe mean accuracy at iteration {i} is: {valid_accuracy[-1]*100}\")\n",
        "\n",
        "            model.train()                                                       #Put the model back in trianing mode\n",
        "\n",
        "    return loss_tracker, valid_accuracy, valid_avg_halting, ponder_valid_acc, ponder_valid_avg_prob, model, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opT8XA8UbpYJ",
        "outputId": "02a3cadc-dea8-48ff-c172-248045e4b4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss at epoch 0 is: 0.6967188715934753\n",
            "\n",
            "The mean accuracy at iteration 0 is: 52.0\n",
            "The loss at epoch 1000 is: 0.6946810483932495\n",
            "The loss at epoch 2000 is: 0.6926469206809998\n"
          ]
        }
      ],
      "source": [
        "loss_tracker, valid_accuracy, valid_avg_halting, ponder_valid_acc, ponder_valid_avg_prob, model, device = train(seed=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaSjrMc19GgL"
      },
      "source": [
        "#Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SUUPoe09Lza"
      },
      "source": [
        "###Total Loss over Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHLShoJkcNuV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''\n",
        "Plot the Total Loss over epochs\n",
        "'''\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.plot([x*1000 for x in range(len(loss_tracker))], loss_tracker)\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss Value', fontsize=14)\n",
        "plt.title(\"Training Loss over Epochs\", fontsize=18)\n",
        "plt.savefig(\"8 Feat Training Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6bVorVD9VWX"
      },
      "source": [
        "###Validation Accuracy over epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADyuXsSE6_GE"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Plot the Accuracy of the Validation set over epochs\n",
        "'''\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.plot([x*5000 for x in range(len(valid_accuracy))], valid_accuracy, c='coral')\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.title(\"Validation Accuracy over Epochs\", fontsize=18)\n",
        "plt.savefig(\"8 Feat Validation Acc\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU_A9cum_mdF"
      },
      "source": [
        "###Average Halting Step over Epochs during Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ZfLQL2_A1b"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Plot the Average Halting Step of the Validation set over epochs\n",
        "'''\n",
        "# print(ponder_valid_acc)\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.plot([x*5000 for x in range(len(valid_avg_halting))], valid_avg_halting, color='seagreen')\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Halting Step', fontsize=14)\n",
        "plt.title(\"Average Halting Step over Epochs\", fontsize=18)\n",
        "plt.savefig(\"Feat Avg Halting\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cf1xyoUSO_8"
      },
      "source": [
        "###Prediction Accuracy of Model over Ponder Steps during Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCdyNlNUTfX1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Plot the Accuracy over Ponder Steps\n",
        "'''\n",
        "for i in range(len(ponder_valid_acc)):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    plt.bar(list(range(1, len(ponder_valid_acc[i])+1)), ponder_valid_acc[i], color='darkcyan')\n",
        "    plt.xlabel('Ponder Step', fontsize=14)\n",
        "    plt.ylabel('Prediction Accuracy', fontsize=14)\n",
        "    plt.title(f\"Prediction Accuracy by Ponder Step at Epoch {i*4000}\", fontsize=18)\n",
        "    plt.ylim(0,1.0)\n",
        "    plt.savefig(f\"Hard Sample Pred. Acc. {i}.png\")\n",
        "    # plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhLROChL7NtX"
      },
      "source": [
        "###Predicted Values Probability Distribution during Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XKMGRLRvMej"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Plot the Probability Distribution of the Predictions\n",
        "'''\n",
        "for i in range(len(ponder_valid_avg_prob)):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    plt.bar(list(range(1, len(ponder_valid_avg_prob[i])+1)), ponder_valid_avg_prob[i], color='crimson')\n",
        "    plt.xlabel('Ponder Step', fontsize=14)\n",
        "    plt.ylabel('Geometric Probability', fontsize=14)\n",
        "    plt.title(f\"Prob. Distribution of Predictions at Epoch {i*4000}\", fontsize=18)\n",
        "    plt.savefig(f\"Hard Prob. Dist {i}.png\")\n",
        "    plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Vi-cvOBtov"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIJituFxCtoF"
      },
      "source": [
        "##Allow Halting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEM1MNE9_fk3"
      },
      "outputs": [],
      "source": [
        "#Create test dataloader\n",
        "test_set = CustomData(8, 64*10, 2)                                              #Generate evaluation data\n",
        "test_data = torch.utils.data.DataLoader(test_set, batch_size=64,num_workers=2)\n",
        "\n",
        "model.eval()                                                                    #Put the model in evaluation mode\n",
        "with torch.no_grad():                                                           #Don't update the model's gradients\n",
        "    epoch_test_acc = []\n",
        "    halt_steps = []\n",
        "\n",
        "    for t_data in test_data:\n",
        "\n",
        "        features, labels = t_data\n",
        "        features, labels = (features.to(device, torch.float32), \n",
        "                            labels.to(device, torch.float32))\n",
        "\n",
        "        test_preds, test_probs, test_batch_halt_idx, halt_step = (\n",
        "            model(features, True))                                              #Get outputs from model\n",
        "\n",
        "        halt_steps.append(halt_step)\n",
        "\n",
        "        '''https://pytorch.org/docs/stable/generated/torch.gather.html\n",
        "        torch.gather uses the indeces passed to retrieve from the \n",
        "        row and the column index of the index to retrieve from the \n",
        "        column of the passed vector (in this case)\n",
        "        '''\n",
        "        test_batch_halt_preds = torch.gather(test_preds, 0, \n",
        "            test_batch_halt_idx[None, :].to(torch.int64)-1)[0]\n",
        "\n",
        "        #Calculate and store the mean accuracy of halted predicitons against the labels \n",
        "        epoch_test_acc.append(np.mean([1 \n",
        "            if ((test_batch_halt_preds[x] > 0) == labels[x]) \n",
        "                else 0 for x in range(\n",
        "                    test_batch_halt_preds.shape[0])]))\n",
        "\n",
        "\n",
        "    print(f\"\\nThe final mean running all steps is: {np.mean(epoch_test_acc)}\")\n",
        "    print(f\"\\nThe average halting step was: {np.mean(halt_steps)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsokZqDQCwoS"
      },
      "source": [
        "##Run all Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkRpstoqC17u"
      },
      "outputs": [],
      "source": [
        "model.eval()                                                                    #Put the model in evaluation mode\n",
        "with torch.no_grad():                                                           #Don't update the model's gradients\n",
        "    halt_steps = []\n",
        "    epoch_test_acc = []\n",
        "\n",
        "    for t_data in test_data:\n",
        "        features, labels = t_data\n",
        "        features, labels = (features.to(device,torch.float32), \n",
        "                            labels.to(device, torch.float32))\n",
        "\n",
        "        test_preds, test_probs, test_batch_halt_idx, halt_step = (\n",
        "            model(features))                                                    #Get outputs from model\n",
        "\n",
        "        halt_steps.append(halt_step)\n",
        "\n",
        "        '''https://pytorch.org/docs/stable/generated/torch.gather.html\n",
        "        torch.gather uses the indeces passed to retrieve from the \n",
        "        row and the column index of the index to retrieve from the \n",
        "        column of the passed vector (in this case)\n",
        "        '''\n",
        "        test_batch_halt_preds = torch.gather(test_preds, 0, \n",
        "            test_batch_halt_idx[None, :].to(torch.int64)-1)[0]\n",
        "\n",
        "        #Calculate and store the mean accuracy of halted predicitons against the labels \n",
        "        epoch_test_acc.append(np.mean([1 \n",
        "            if ((test_batch_halt_preds[x] > 0) == labels[x]) \n",
        "                else 0 for x in range(\n",
        "                    test_batch_halt_preds.shape[0])]))\n",
        "\n",
        "\n",
        "    print(f\"\\nThe final mean running all steps is: {np.mean(epoch_test_acc)}\")\n",
        "    print(f\"\\nThe average halting step was: {np.mean(halt_steps)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ParityPonderNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}