{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IHpoaVFw7oz",
        "outputId": "87ee23a0-1521-4acb-dbc7-9308c62edcad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KBBJ12OJai9o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import import_ipynb\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"mnt\")\n",
        "%cd \"mnt/My Drive/Colab Notebooks/Advanced ML/PonderNet\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MON2A988xUnu",
        "outputId": "b97d5c9c-1431-4312-c15a-9ce6d5d27ffa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at mnt\n",
            "/content/mnt/My Drive/Colab Notebooks/Advanced ML/PonderNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ParityPonderNet as Chird"
      ],
      "metadata": {
        "id": "iqmSafI3yG2y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Ex:"
      ],
      "metadata": {
        "id": "khUPCn7vP8wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo_data = Chird.CustomData(8, 10, 0)                                                #Create dataset with 100 samples of 8 features each with seed 0"
      ],
      "metadata": {
        "id": "WB8Q9YU-QDO6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"No. of samples: {len(demo_data)}\")\n",
        "data_sample = demo_data[0]\n",
        "print(f\"Sample 10 Fetures: {data_sample[0]}\")\n",
        "print(f\"Sample 10 Parity: {data_sample[1]}\")"
      ],
      "metadata": {
        "id": "qxxQG-PmQSE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6dded85-62cd-454c-eb0c-47f14722031b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of samples: 10\n",
            "Sample 10 Fetures: tensor([-1.,  0., -1.,  0.,  0.,  1., -1.,  1.])\n",
            "Sample 10 Parity: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_dataloader = torch.utils.data.DataLoader(demo_data, \n",
        "                batch_size=2, num_workers=2)                                    #Create dataloader and stream data in batches\n",
        "\n",
        "\n",
        "for x,y in demo_dataloader:                                                     #Each iteration streams <= sample/batch_size no. of data items (< on the last iteration if not divisible)\n",
        "    print(f\"Features are: {x}\\n\")\n",
        "    print(f\"Target is: {y}\")\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "PW6cMAZEQTdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55b59c1-165b-4234-8d18-485da6ce1865"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features are: tensor([[ 1.,  1., -1.,  1.,  1.,  1., -1., -1.],\n",
            "        [ 0.,  1.,  0.,  1.,  1., -1.,  1.,  1.]])\n",
            "\n",
            "Target is: tensor([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Ex:"
      ],
      "metadata": {
        "id": "5hwj_eT_XBD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")           #Specify which resource to use\n",
        "\n",
        "model = Chird.ParityPonderNetwork(8, nn.GRUCell, 5, \n",
        "                64, seed=0).to(device, torch.float32)                           #Init the model wth GRU step-function              \n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)                     #Init the optimizer with Adam algorithm and learning rate of 0.0003"
      ],
      "metadata": {
        "id": "ABeUfRCwTgYo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in demo_dataloader:                                                     \n",
        "\n",
        "    features, labels = x.to(device, torch.float32), y.to(device, \n",
        "                        torch.float32)                                          #Attach the fetures and labels to the device\n",
        "    \n",
        "    predictions, probabilities, _, _ = model(features, demo=True)               #Run forward propogation for PonderNet\n",
        "    break"
      ],
      "metadata": {
        "id": "Ijs8RgGzX-ND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f95a1a-91ec-4fd8-982a-2855011eae77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********************************************PONDER STEP 0**************************************************\n",
            "\n",
            "The hidden states are: tensor([[ 0.0744,  0.0085,  0.0140,  0.0910, -0.0647, -0.0382, -0.0912, -0.0809,\n",
            "          0.0560, -0.0381,  0.0811, -0.1058, -0.1844,  0.1014,  0.0775,  0.0974,\n",
            "         -0.0413, -0.0663, -0.0702,  0.1249, -0.0238,  0.1550, -0.0129,  0.0297,\n",
            "         -0.0467, -0.0330,  0.1171,  0.0295, -0.0932, -0.0182, -0.0583,  0.0359,\n",
            "         -0.0564, -0.0211, -0.1543, -0.0022,  0.0010, -0.1314,  0.0515, -0.1607,\n",
            "         -0.0400, -0.1312, -0.1036, -0.0315,  0.0851,  0.0578,  0.1147, -0.0645,\n",
            "         -0.0649, -0.0611, -0.0661,  0.0726, -0.0079, -0.0694, -0.0110,  0.0355,\n",
            "          0.0476,  0.0510, -0.0137, -0.0473,  0.0501,  0.0377, -0.0847, -0.0301],\n",
            "        [ 0.0775, -0.0548, -0.0422,  0.0977, -0.0339,  0.0744,  0.0317,  0.1150,\n",
            "          0.0120, -0.2050,  0.1565,  0.1546, -0.1033,  0.0624, -0.0599,  0.0008,\n",
            "         -0.0234,  0.0638,  0.0385,  0.0113, -0.0985,  0.1004,  0.1095, -0.1004,\n",
            "          0.0806, -0.1199, -0.0602, -0.1212,  0.0536, -0.0912,  0.1148, -0.0948,\n",
            "         -0.0480, -0.0633,  0.0444, -0.0194,  0.0186, -0.0096,  0.0275,  0.0217,\n",
            "         -0.0817, -0.0212,  0.0358,  0.1563, -0.0994,  0.1297,  0.1407,  0.1289,\n",
            "         -0.0082,  0.0023,  0.0433,  0.1627,  0.0602, -0.0530, -0.1461,  0.0700,\n",
            "          0.0860,  0.0836, -0.0297,  0.0632, -0.0097,  0.0489, -0.0994, -0.0576]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "The lambdas are: tensor([0.4744, 0.4744], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Bernoulli sample: tensor([0., 1.], grad_fn=<BernoulliBackward0>)\n",
            "The batch halt indeces are: tensor([0., 1.], grad_fn=<IndexPutBackward0>)\n",
            "\n",
            "The unhalted probabilities are: tensor([0.5256, 0.5256], grad_fn=<MulBackward0>)\n",
            "\n",
            "The predictions are: tensor([[ 0.0686,  0.0686],\n",
            "        [10.0000, 10.0000],\n",
            "        [10.0000, 10.0000],\n",
            "        [10.0000, 10.0000],\n",
            "        [10.0000, 10.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "The probabilities are: tensor([[0.4744, 0.4744],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.0000, 0.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "**********************************************PONDER STEP 1**************************************************\n",
            "\n",
            "The hidden states are: tensor([[ 0.1141,  0.0144,  0.0221,  0.1368, -0.0934, -0.0547, -0.1396, -0.1136,\n",
            "          0.0888, -0.0524,  0.0984, -0.1517, -0.2801,  0.1582,  0.1021,  0.1606,\n",
            "         -0.0628, -0.1078, -0.0978,  0.2172, -0.0224,  0.2309, -0.0090,  0.0359,\n",
            "         -0.0660, -0.0365,  0.1815,  0.0207, -0.1486, -0.0107, -0.0951,  0.0574,\n",
            "         -0.1038, -0.0557, -0.2200,  0.0018,  0.0028, -0.1999,  0.0801, -0.2338,\n",
            "         -0.0481, -0.1830, -0.1530, -0.0534,  0.1223,  0.0890,  0.1847, -0.0974,\n",
            "         -0.1019, -0.0884, -0.0896,  0.1040, -0.0081, -0.1163, -0.0031,  0.0504,\n",
            "          0.0756,  0.0615, -0.0351, -0.0844,  0.0883,  0.0574, -0.1186, -0.0427],\n",
            "        [ 0.0901, -0.0933, -0.0853,  0.1594, -0.0386,  0.1159,  0.0421,  0.1691,\n",
            "         -0.0093, -0.3029,  0.2233,  0.2289, -0.1685,  0.0997, -0.0817, -0.0136,\n",
            "         -0.0301,  0.0984,  0.0530,  0.0199, -0.1650,  0.1467,  0.1562, -0.1512,\n",
            "          0.1375, -0.1864, -0.1025, -0.1931,  0.0806, -0.1344,  0.1628, -0.1387,\n",
            "         -0.0682, -0.0953,  0.0592, -0.0203,  0.0487, -0.0154,  0.0617,  0.0201,\n",
            "         -0.1160, -0.0264,  0.0313,  0.2368, -0.1645,  0.1894,  0.2154,  0.1902,\n",
            "          0.0026,  0.0055,  0.0514,  0.2472,  0.1086, -0.0841, -0.2385,  0.1016,\n",
            "          0.1094,  0.1132, -0.0570,  0.0925, -0.0081,  0.0626, -0.1563, -0.0926]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "The lambdas are: tensor([0.4989, 0.4606], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Bernoulli sample: tensor([1., 1.], grad_fn=<BernoulliBackward0>)\n",
            "The batch halt indeces are: tensor([2., 1.], grad_fn=<IndexPutBackward0>)\n",
            "\n",
            "The unhalted probabilities are: tensor([0.2634, 0.2835], grad_fn=<MulBackward0>)\n",
            "\n",
            "The predictions are: tensor([[ 0.0686,  0.0686],\n",
            "        [ 0.1101,  0.0688],\n",
            "        [10.0000, 10.0000],\n",
            "        [10.0000, 10.0000],\n",
            "        [10.0000, 10.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "The probabilities are: tensor([[0.4744, 0.4744],\n",
            "        [0.2622, 0.2421],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.0000, 0.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "**********************************************PONDER STEP 2**************************************************\n",
            "\n",
            "The hidden states are: tensor([[ 0.1361,  0.0199,  0.0257,  0.1604, -0.1062, -0.0615, -0.1662, -0.1262,\n",
            "          0.1091, -0.0559,  0.0932, -0.1712, -0.3303,  0.1894,  0.1046,  0.2028,\n",
            "         -0.0736, -0.1334, -0.1076,  0.2803, -0.0140,  0.2708, -0.0039,  0.0357,\n",
            "         -0.0732, -0.0302,  0.2139,  0.0037, -0.1818,  0.0007, -0.1212,  0.0677,\n",
            "         -0.1373, -0.0885, -0.2483,  0.0067,  0.0018, -0.2317,  0.0959, -0.2698,\n",
            "         -0.0459, -0.2003, -0.1773, -0.0676,  0.1395,  0.1050,  0.2251, -0.1133,\n",
            "         -0.1226, -0.1005, -0.0960,  0.1192, -0.0071, -0.1455,  0.0093,  0.0550,\n",
            "          0.0942,  0.0562, -0.0534, -0.1115,  0.1153,  0.0672, -0.1329, -0.0507],\n",
            "        [ 0.0828, -0.1166, -0.1150,  0.1997, -0.0353,  0.1389,  0.0424,  0.1926,\n",
            "         -0.0345, -0.3542,  0.2525,  0.2655, -0.2073,  0.1226, -0.0889, -0.0281,\n",
            "         -0.0334,  0.1147,  0.0578,  0.0260, -0.2075,  0.1668,  0.1749, -0.1753,\n",
            "          0.1746, -0.2215, -0.1307, -0.2342,  0.0939, -0.1557,  0.1823, -0.1516,\n",
            "         -0.0767, -0.1127,  0.0614, -0.0174,  0.0749, -0.0185,  0.0882,  0.0143,\n",
            "         -0.1281, -0.0277,  0.0187,  0.2780, -0.2077,  0.2183,  0.2523,  0.2183,\n",
            "          0.0142,  0.0120,  0.0509,  0.2897,  0.1408, -0.1015, -0.2936,  0.1149,\n",
            "          0.1110,  0.1213, -0.0768,  0.1079, -0.0055,  0.0636, -0.1893, -0.1164]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "The lambdas are: tensor([0.5094, 0.4563], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Bernoulli sample: tensor([0., 0.], grad_fn=<BernoulliBackward0>)\n",
            "The batch halt indeces are: tensor([2., 1.], grad_fn=<IndexPutBackward0>)\n",
            "\n",
            "The unhalted probabilities are: tensor([0.1292, 0.1541], grad_fn=<MulBackward0>)\n",
            "\n",
            "The predictions are: tensor([[ 0.0686,  0.0686],\n",
            "        [ 0.1101,  0.0688],\n",
            "        [ 0.1423,  0.0689],\n",
            "        [10.0000, 10.0000],\n",
            "        [10.0000, 10.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "The probabilities are: tensor([[0.4744, 0.4744],\n",
            "        [0.2622, 0.2421],\n",
            "        [0.1342, 0.1294],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.0000, 0.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "**********************************************PONDER STEP 3**************************************************\n",
            "\n",
            "The hidden states are: tensor([[ 0.1492,  0.0248,  0.0265,  0.1728, -0.1119, -0.0637, -0.1810, -0.1315,\n",
            "          0.1224, -0.0545,  0.0820, -0.1793, -0.3570,  0.2068,  0.0996,  0.2309,\n",
            "         -0.0790, -0.1482, -0.1105,  0.3213, -0.0051,  0.2925, -0.0011,  0.0348,\n",
            "         -0.0752, -0.0221,  0.2295, -0.0116, -0.2015,  0.0104, -0.1399,  0.0716,\n",
            "         -0.1594, -0.1144, -0.2614,  0.0108, -0.0011, -0.2441,  0.1049, -0.2896,\n",
            "         -0.0419, -0.2036, -0.1894, -0.0760,  0.1479,  0.1128,  0.2472, -0.1206,\n",
            "         -0.1340, -0.1057, -0.0964,  0.1279, -0.0066, -0.1619,  0.0209,  0.0548,\n",
            "          0.1074,  0.0467, -0.0666, -0.1305,  0.1333,  0.0713, -0.1394, -0.0574],\n",
            "        [ 0.0719, -0.1292, -0.1327,  0.2260, -0.0315,  0.1513,  0.0386,  0.2023,\n",
            "         -0.0552, -0.3825,  0.2656,  0.2839, -0.2297,  0.1372, -0.0905, -0.0387,\n",
            "         -0.0366,  0.1211,  0.0588,  0.0301, -0.2338,  0.1751,  0.1820, -0.1855,\n",
            "          0.1975, -0.2390, -0.1487, -0.2570,  0.1002, -0.1665,  0.1895, -0.1511,\n",
            "         -0.0808, -0.1234,  0.0599, -0.0148,  0.0938, -0.0201,  0.1057,  0.0097,\n",
            "         -0.1309, -0.0286,  0.0078,  0.2987, -0.2358,  0.2321,  0.2693,  0.2302,\n",
            "          0.0224,  0.0199,  0.0492,  0.3103,  0.1598, -0.1109, -0.3248,  0.1202,\n",
            "          0.1065,  0.1224, -0.0888,  0.1171, -0.0038,  0.0616, -0.2084, -0.1331]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "The lambdas are: tensor([0.5140, 0.4554], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Bernoulli sample: tensor([1., 1.], grad_fn=<BernoulliBackward0>)\n",
            "The batch halt indeces are: tensor([2., 1.], grad_fn=<IndexPutBackward0>)\n",
            "\n",
            "The unhalted probabilities are: tensor([0.0628, 0.0839], grad_fn=<MulBackward0>)\n",
            "\n",
            "The predictions are: tensor([[ 0.0686,  0.0686],\n",
            "        [ 0.1101,  0.0688],\n",
            "        [ 0.1423,  0.0689],\n",
            "        [ 0.1664,  0.0687],\n",
            "        [10.0000, 10.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "The probabilities are: tensor([[0.4744, 0.4744],\n",
            "        [0.2622, 0.2421],\n",
            "        [0.1342, 0.1294],\n",
            "        [0.0664, 0.0702],\n",
            "        [0.0000, 0.0000]], grad_fn=<CopySlices>)\n",
            "\n",
            "**********************************************PONDER STEP 4**************************************************\n",
            "\n",
            "The hidden states are: tensor([[ 1.5749e-01,  2.8954e-02,  2.5831e-02,  1.7940e-01, -1.1444e-01,\n",
            "         -6.3764e-02, -1.8952e-01, -1.3426e-01,  1.3143e-01, -5.1552e-02,\n",
            "          7.1020e-02, -1.8273e-01, -3.7158e-01,  2.1697e-01,  9.3361e-02,\n",
            "          2.4948e-01, -8.1607e-02, -1.5594e-01, -1.1108e-01,  3.4704e-01,\n",
            "          2.2166e-03,  3.0433e-01, -4.7172e-04,  3.4475e-02, -7.5318e-02,\n",
            "         -1.5033e-02,  2.3678e-01, -2.3037e-02, -2.1295e-01,  1.7485e-02,\n",
            "         -1.5310e-01,  7.2238e-02, -1.7330e-01, -1.3300e-01, -2.6812e-01,\n",
            "          1.3750e-02, -4.5376e-03, -2.4716e-01,  1.0999e-01, -3.0167e-01,\n",
            "         -3.8502e-02, -2.0178e-01, -1.9537e-01, -8.0555e-02,  1.5253e-01,\n",
            "          1.1640e-01,  2.5892e-01, -1.2407e-01, -1.3997e-01, -1.0789e-01,\n",
            "         -9.5245e-02,  1.3360e-01, -6.7308e-03, -1.7005e-01,  3.0270e-02,\n",
            "          5.2660e-02,  1.1675e-01,  3.7385e-02, -7.5583e-02, -1.4331e-01,\n",
            "          1.4471e-01,  7.2425e-02, -1.4258e-01, -6.3256e-02],\n",
            "        [ 6.2168e-02, -1.3554e-01, -1.4224e-01,  2.4297e-01, -2.8895e-02,\n",
            "          1.5789e-01,  3.3869e-02,  2.0629e-01, -7.0399e-02, -3.9852e-01,\n",
            "          2.7168e-01,  2.9360e-01, -2.4235e-01,  1.4680e-01, -9.0526e-02,\n",
            "         -4.5523e-02, -3.9967e-02,  1.2259e-01,  5.8387e-02,  3.2590e-02,\n",
            "         -2.4980e-01,  1.7851e-01,  1.8474e-01, -1.8877e-01,  2.1126e-01,\n",
            "         -2.4704e-01, -1.5996e-01, -2.6956e-01,  1.0309e-01, -1.7242e-01,\n",
            "          1.9139e-01, -1.4674e-01, -8.3263e-02, -1.3059e-01,  5.8048e-02,\n",
            "         -1.3219e-02,  1.0646e-01, -2.0859e-02,  1.1659e-01,  6.9124e-03,\n",
            "         -1.3054e-01, -2.9806e-02,  1.2863e-04,  3.0899e-01, -2.5379e-01,\n",
            "          2.3825e-01,  2.7672e-01,  2.3463e-01,  2.7427e-02,  2.7478e-02,\n",
            "          4.8263e-02,  3.1975e-01,  1.6991e-01, -1.1582e-01, -3.4179e-01,\n",
            "          1.2201e-01,  1.0150e-01,  1.2197e-01, -9.5048e-02,  1.2340e-01,\n",
            "         -2.8353e-03,  5.9580e-02, -2.1945e-01, -1.4485e-01]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "The lambdas are: tensor([1., 1.])\n",
            "\n",
            "Bernoulli sample: tensor([1., 1.])\n",
            "The batch halt indeces are: tensor([2., 1.], grad_fn=<IndexPutBackward0>)\n",
            "\n",
            "The unhalted probabilities are: tensor([0., 0.], grad_fn=<MulBackward0>)\n",
            "\n",
            "The predictions are: tensor([[0.0686, 0.0686],\n",
            "        [0.1101, 0.0688],\n",
            "        [0.1423, 0.0689],\n",
            "        [0.1664, 0.0687],\n",
            "        [0.1838, 0.0682]], grad_fn=<CopySlices>)\n",
            "\n",
            "The probabilities are: tensor([[0.4744, 0.4744],\n",
            "        [0.2622, 0.2421],\n",
            "        [0.1342, 0.1294],\n",
            "        [0.0664, 0.0702],\n",
            "        [0.0628, 0.0839]], grad_fn=<CopySlices>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss Ex:"
      ],
      "metadata": {
        "id": "CDKqVM37hTdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = Chird.PonderLoss(5, \n",
        "                nn.BCEWithLogitsLoss(reduction='none'), \n",
        "                    0.3, 0.01).to(device, torch.float32)                        #Init the model loss with binary cross-entropy, a lambda probability of 0.3 and beta of 0.01"
      ],
      "metadata": {
        "id": "6QoPO0uwk79l"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Reconstruction Loss"
      ],
      "metadata": {
        "id": "2MpG64PEo1ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(demo_dataloader):                                                     \n",
        "\n",
        "    features, labels = x.to(device, torch.float32), y.to(device, \n",
        "                        torch.float32)\n",
        "    \n",
        "    predictions, probabilities, _, _ = model(features)                          #Run forward propogation for PonderNet\n",
        "    print(f\"*****************************EPOCH {i}***********************************\")\n",
        "\n",
        "    loss = model_loss(probabilities, labels, predictions, True)                 #Compute the total loss of the predictions\n",
        "    '''Set the gradients to 0, compute the gradients and take the gradient \n",
        "    descent step.\n",
        "    ''' \n",
        "    optimizer.zero_grad()                                                       #Clear gradients\n",
        "    loss.backward()                                                             #Compute the gradients\n",
        "    optimizer.step()                                                            #Update the parameters"
      ],
      "metadata": {
        "id": "PM71T9BpZWZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf5a530-2776-4e5c-c07d-7922b099f41a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************EPOCH 0***********************************\n",
            "The probabilities are: tensor([[0.4744, 0.4744],\n",
            "        [0.2449, 0.2526],\n",
            "        [0.1300, 0.1324],\n",
            "        [0.0697, 0.0686],\n",
            "        [0.0810, 0.0719]], grad_fn=<CopySlices>)\n",
            "BCE loss at step 0 = tensor([0.6594, 0.7280], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 0 = tensor([0.3128, 0.3454], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 1 = tensor([0.6462, 0.7471], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 1 = tensor([0.1583, 0.1887], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 2 = tensor([0.6414, 0.7606], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 2 = tensor([0.0834, 0.1007], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 3 = tensor([0.6405, 0.7705], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 3 = tensor([0.0446, 0.0529], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 4 = tensor([0.6408, 0.7781], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 4 = tensor([0.0519, 0.0560], grad_fn=<MulBackward0>)\n",
            "\n",
            "The reconstruction loss is: 0.6973556876182556\n",
            "\n",
            "\n",
            "*****************************EPOCH 1***********************************\n",
            "The probabilities are: tensor([[0.4745, 0.4745],\n",
            "        [0.2399, 0.2583],\n",
            "        [0.1285, 0.1330],\n",
            "        [0.0704, 0.0671],\n",
            "        [0.0867, 0.0671]], grad_fn=<CopySlices>)\n",
            "BCE loss at step 0 = tensor([0.6596, 0.6596], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 0 = tensor([0.3130, 0.3130], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 1 = tensor([0.6931, 0.6738], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 1 = tensor([0.1663, 0.1740], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 2 = tensor([0.7078, 0.6729], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 2 = tensor([0.0909, 0.0895], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 3 = tensor([0.7139, 0.6689], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 3 = tensor([0.0502, 0.0449], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 4 = tensor([0.7162, 0.6652], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 4 = tensor([0.0621, 0.0447], grad_fn=<MulBackward0>)\n",
            "\n",
            "The reconstruction loss is: 0.6742735505104065\n",
            "\n",
            "\n",
            "*****************************EPOCH 2***********************************\n",
            "The probabilities are: tensor([[0.4746, 0.4746],\n",
            "        [0.2628, 0.2572],\n",
            "        [0.1348, 0.1324],\n",
            "        [0.0664, 0.0672],\n",
            "        [0.0614, 0.0686]], grad_fn=<CopySlices>)\n",
            "BCE loss at step 0 = tensor([0.6595, 0.6595], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 0 = tensor([0.3130, 0.3130], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 1 = tensor([0.6466, 0.6589], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 1 = tensor([0.1699, 0.1695], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 2 = tensor([0.6437, 0.6565], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 2 = tensor([0.0868, 0.0869], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 3 = tensor([0.6426, 0.6532], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 3 = tensor([0.0427, 0.0439], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 4 = tensor([0.6416, 0.6498], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 4 = tensor([0.0394, 0.0446], grad_fn=<MulBackward0>)\n",
            "\n",
            "The reconstruction loss is: 0.6547847986221313\n",
            "\n",
            "\n",
            "*****************************EPOCH 3***********************************\n",
            "The probabilities are: tensor([[0.4746, 0.4746],\n",
            "        [0.2448, 0.2512],\n",
            "        [0.1299, 0.1311],\n",
            "        [0.0697, 0.0683],\n",
            "        [0.0810, 0.0748]], grad_fn=<CopySlices>)\n",
            "BCE loss at step 0 = tensor([0.7281, 0.7281], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 0 = tensor([0.3455, 0.3455], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 1 = tensor([0.7379, 0.6942], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 1 = tensor([0.1807, 0.1744], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 2 = tensor([0.7462, 0.6806], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 2 = tensor([0.0969, 0.0892], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 3 = tensor([0.7519, 0.6758], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 3 = tensor([0.0524, 0.0462], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 4 = tensor([0.7557, 0.6748], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 4 = tensor([0.0612, 0.0505], grad_fn=<MulBackward0>)\n",
            "\n",
            "The reconstruction loss is: 0.7212825417518616\n",
            "\n",
            "\n",
            "*****************************EPOCH 4***********************************\n",
            "The probabilities are: tensor([[0.4746, 0.4746],\n",
            "        [0.2507, 0.2402],\n",
            "        [0.1309, 0.1281],\n",
            "        [0.0684, 0.0700],\n",
            "        [0.0753, 0.0872]], grad_fn=<CopySlices>)\n",
            "BCE loss at step 0 = tensor([0.6593, 0.7282], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 0 = tensor([0.3129, 0.3456], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 1 = tensor([0.6375, 0.6937], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 1 = tensor([0.1598, 0.1666], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 2 = tensor([0.6284, 0.6794], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 2 = tensor([0.0823, 0.0870], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 3 = tensor([0.6238, 0.6729], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 3 = tensor([0.0427, 0.0471], grad_fn=<MulBackward0>)\n",
            "BCE loss at step 4 = tensor([0.6209, 0.6697], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Weighted loss at step 4 = tensor([0.0468, 0.0584], grad_fn=<MulBackward0>)\n",
            "\n",
            "The reconstruction loss is: 0.6745740175247192\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Regularization Loss"
      ],
      "metadata": {
        "id": "pXPguGQ0hY3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create initial probability distribution\n",
        "p_not_halted = 1.                                                               #Helper variable that lets us know the probability of not stoppping at the current step\n",
        "geometric_probs = []\n",
        "for _ in range(5):\n",
        "    geometric_probs.append(p_not_halted * 0.3)\n",
        "    p_not_halted = p_not_halted * (1-0.3)                                       #Update the probs. of not halting; this follows a geometric distribution as it continuously reduces\n",
        "\n",
        "print(f\"List representation geometric_probabaility distributino: {geometric_probs}\\n\")\n",
        "print(f\"The sum of the geometric prob. distribution: {sum(geometric_probs)}\")"
      ],
      "metadata": {
        "id": "zKxbvFd1hcVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f65f6a-53ee-4d08-8d35-9ab3505437a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List representation geometric_probabaility distributino: [0.3, 0.21, 0.14699999999999996, 0.10289999999999998, 0.07202999999999997]\n",
            "\n",
            "The sum of the geometric prob. distribution: 0.83193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(demo_dataloader):                                                     \n",
        "\n",
        "    features, labels = x.to(device, torch.float32), y.to(device, \n",
        "                        torch.float32)\n",
        "    \n",
        "    predictions, probabilities, _, _ = model(features)                          #Run forward propogation for PonderNet\n",
        "    print(f\"*****************************EPOCH {i}***********************************\")\n",
        "    loss = model_loss(probabilities, labels, predictions, demo_reg=True)        #Compute the total loss of the predictions\n",
        "    '''Set the gradients to 0, compute the gradients and take the gradient \n",
        "    descent step.\n",
        "    ''' \n",
        "    optimizer.zero_grad()                                                       #Clear gradients\n",
        "    loss.backward()                                                             #Compute the gradients\n",
        "    optimizer.step()                                                            #Update the parameters"
      ],
      "metadata": {
        "id": "UwcxwN4wiQdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe189473-bb6f-48f4-d794-7338965cb7d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************EPOCH 0***********************************\n",
            "The probabilities are: tensor([[0.4745, 0.2405, 0.1283, 0.0701, 0.0866],\n",
            "        [0.4745, 0.2563, 0.1330, 0.0677, 0.0685]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "Batch geo probs: tensor([[0.3000, 0.2100, 0.1470, 0.1029, 0.0720],\n",
            "        [0.3000, 0.2100, 0.1470, 0.1029, 0.0720]])\n",
            "\n",
            "The regularisation loss is: -0.1188916563987732\n",
            "\n",
            "\n",
            "*****************************EPOCH 1***********************************\n",
            "The probabilities are: tensor([[0.4745, 0.2599, 0.1332, 0.0667, 0.0657],\n",
            "        [0.4745, 0.2530, 0.1323, 0.0684, 0.0718]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "Batch geo probs: tensor([[0.3000, 0.2100, 0.1470, 0.1029, 0.0720],\n",
            "        [0.3000, 0.2100, 0.1470, 0.1029, 0.0720]])\n",
            "\n",
            "The regularisation loss is: -0.1177581325173378\n",
            "\n",
            "\n",
            "*****************************EPOCH 2***********************************\n",
            "The probabilities are: tensor([[0.4745, 0.2469, 0.1299, 0.0690, 0.0797],\n",
            "        [0.4745, 0.2640, 0.1343, 0.0659, 0.0613]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "Batch geo probs: tensor([[0.3000, 0.2100, 0.1470, 0.1029, 0.0720],\n",
            "        [0.3000, 0.2100, 0.1470, 0.1029, 0.0720]])\n",
            "\n",
            "The regularisation loss is: -0.11719761788845062\n",
            "\n",
            "\n",
            "*****************************EPOCH 3***********************************\n",
            "The probabilities are: tensor([[0.4744, 0.2429, 0.1294, 0.0700, 0.0833],\n",
            "        [0.4744, 0.2627, 0.1348, 0.0665, 0.0616]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "Batch geo probs: tensor([[0.3000, 0.2100, 0.1470, 0.1029, 0.0720],\n",
            "        [0.3000, 0.2100, 0.1470, 0.1029, 0.0720]])\n",
            "\n",
            "The regularisation loss is: -0.11782070249319077\n",
            "\n",
            "\n",
            "*****************************EPOCH 4***********************************\n",
            "The probabilities are: tensor([[0.4744, 0.2562, 0.1328, 0.0677, 0.0689],\n",
            "        [0.4744, 0.2357, 0.1261, 0.0702, 0.0936]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "Batch geo probs: tensor([[0.3000, 0.2100, 0.1470, 0.1029, 0.0720],\n",
            "        [0.3000, 0.2100, 0.1470, 0.1029, 0.0720]])\n",
            "\n",
            "The regularisation loss is: -0.11834307014942169\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Halting Ex:"
      ],
      "metadata": {
        "id": "nd6r85LIseiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (x,y) in enumerate(demo_dataloader):                                                     \n",
        "\n",
        "        features, labels = x.to(device, torch.float32), y.to(device, \n",
        "                            torch.float32)\n",
        "        \n",
        "        predictions, probabilities, _, _ = model(features, is_prediction=True, \n",
        "                                                demo_halting=True)                 #Run forward propogation for PonderNet"
      ],
      "metadata": {
        "id": "naLJfU0Groft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be1638f-43b3-4b25-e311-e48840ff3295"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The halted batch indeces are: tensor([5., 3.])\n",
            "The batch was halted at ponder step: 4\n",
            "\n",
            "The halted batch indeces are: tensor([1., 1.])\n",
            "The batch was halted at ponder step: 0\n",
            "\n",
            "The halted batch indeces are: tensor([1., 1.])\n",
            "The batch was halted at ponder step: 0\n",
            "\n",
            "The halted batch indeces are: tensor([2., 3.])\n",
            "The batch was halted at ponder step: 2\n",
            "\n",
            "The halted batch indeces are: tensor([2., 2.])\n",
            "The batch was halted at ponder step: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bVGhY7pTtnxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ParityPonderNet Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}